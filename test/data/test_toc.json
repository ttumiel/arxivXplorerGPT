{"ada": "1. Introduction (756 words, 1 figure)\n2. Adaptive Agent (AdA) (2648 words)\n  2.1. Open-ended task space: XLand 2.0 (556 words, 1 figure)\n  2.2. Meta-RL (346 words)\n  2.3. Auto-curriculum learning (470 words)\n  2.4. RL agent (793 words, 1 figure)\n  2.5. Distillation (357 words, 1 figure)\n3. Experiments and Results (4635 words)\n  3.1. AdA shows human-timescale adaptation (1377 words, 5 figures)\n  3.2. Architecture influences performance (137 words)\n  3.3. Auto-curriculum learning improves performance (258 words, 1 figure)\n  3.4. Scaling the agent increases performance (712 words, 2 figures)\n  3.5. Scaling the task pool increases performance (427 words, 1 figure)\n  3.6. Distillation improves performance and enables scaling agents (395 words, 2 figures)\n  3.7. Training on more trials with skip memory enables many-shot adaptation (636 words, 1 figure)\n  3.8. AdA can leverage prompting with first-person demonstrations (271 words)\n4. Related Work (889 words)\n5. Conclusion (385 words)\n6. Authors and Contributions (248 words)\n  6.1. Core contributors (135 words)\n  6.2. Partial contributors (72 words)\n  6.3. Sponsors (10 words)\n7. Acknowledgements (130 words)\n8. Appendix (0 words)\n9. Environment Details (706 words)\n  9.1. XLand 2.0 (269 words)\n  9.2. Pre-sampling tasks for training (429 words)\n10. Evaluation (1335 words)\n  10.1. Test scores (447 words)\n  10.2. Hand-authored probe tasks (126 words)\n  10.3. Adaptation metric (491 words, 4 figures)\n  10.4. Human data collection (254 words, 1 figure)\n11. Agent Details (935 words)\n  11.1. Agent Architecture (473 words)\n  11.2. Observations (444 words)\n12. Training Details (3061 words)\n  12.1. Meta-RL (202 words)\n  12.2. Single-agent training (168 words)\n  12.3. Multi-agent training (232 words)\n  12.4. Architecture experiments (53 words)\n  12.5. Auto-curriculum learning (1450 words, 3 figures)\n  12.6. Distillation teacher for scaling experiments (82 words)\n  12.7. Scaling the network (314 words)\n  12.8. Scaling the memory length (83 words)\n  12.9. Scaling the size of the task pool (67 words)\n  12.10. Scaling the complexity of the task pool (192 words)\n  12.11. Distillation enables scaling agents (66 words)\n  12.12. Training on more trials with skip memory (92 words)\n13. Additional Experiments (1873 words)\n  13.1. Multi-agent adaptation (206 words, 2 figures)\n  13.2. Conditioning on number of shots doesn\u2019t affect agents\u2019 performance (303 words, 1 figure)\n  13.3. Scaling complexity of the task pool (376 words, 1 figure)\n  13.4. Computational cost (859 words, 5 figures)\n  13.5. Repeated distillation (103 words)\n14. Human-Timescale Adaptation (3845 words)\n  14.1. Probe tasks (2507 words)\n  14.2. Comparing human and agent scores on every probe task (116 words, 1 figure)\n  14.3. Quantifying stochasticity (279 words, 2 figures)\n  14.4. Prompting through first-person demonstrations (907 words, 3 figures)", "FP8": "1.  (63 words)\n2. Introduction (1062 words, 1 figure)\n3. FP8 LLMs (2365 words)\n  3.1. FP8 Gradient and All-Reduce Communication (722 words)\n  3.2. FP8 Optimizer (528 words)\n  3.3. FP8 Distributed Parallel Training (740 words, 2 figures)\n4. Experiment (2331 words)\n  4.1. Experimental Setup (633 words)\n    4.1.1. Training Dataset (162 words)\n    4.1.2. Model Configuration (467 words, 1 figure)\n  4.2. Main Results (945 words)\n    4.2.1. Model Performance (447 words, 2 figures)\n    4.2.2. System Performance (492 words, 1 figure)\n  4.3. Ablation Study (674 words, 1 figure)\n5. Related Work (697 words)\n6. Conclusion (134 words)\n7. Contribution and Acknowledgement (179 words)\n8. Appendix (1507 words)\n  8.1. FP8 Data Formats (570 words)\n  8.2. FP8 Tensor Scaling (439 words, 1 figure)\n  8.3. Pre-training Data (487 words)", "instructgpt": "1. Introduction (1508 words, 1 figure)\n2. Related work (720 words)\n3. Methods and experimental details (3164 words)\n  3.1. High-level methodology (310 words)\n  3.2. Dataset (510 words)\n  3.3. Tasks (224 words)\n  3.4. Human data collection (341 words)\n  3.5. Models (976 words)\n  3.6. Evaluation (786 words, 1 figure)\n4. Results (3149 words)\n  4.1. Results on the API distribution (822 words, 2 figures)\n  4.2. Results on public NLP datasets (1870 words, 2 figures)\n  4.3. Qualitative results (408 words)\n5. Discussion (3112 words)\n  5.1. Implications for alignment research (643 words)\n  5.2. Who are we aligning to? (696 words)\n  5.3. Limitations (358 words)\n  5.4. Open questions (622 words)\n  5.5. Broader impacts (414 words)\n  5.6. Acknowledgements (356 words)\n6. Additional prompt data details (2685 words)\n  6.1. Labeler-written prompts (261 words)\n  6.2. API user prompts (1574 words)\n    6.2.1. Illustrative user prompts from InstructGPT distribution (823 words)\n    6.2.2. Illustrative user prompts from GPT-3 distribution (528 words)\n  6.3. Dataset sizes (208 words)\n  6.4. Data diversity (627 words)\n7. Additional human data collection details (2424 words)\n  7.1. Labeler selection (1692 words)\n  7.2. Labeling instructions (338 words)\n  7.3. Labeler demographic data (215 words)\n  7.4. Labeler satisfaction survey (138 words, 1 figure)\n  7.5. Web interface (22 words)\n8. Additional model details (1347 words)\n  8.1. Details of SFT training (120 words)\n  8.2. Details of RM training (290 words)\n  8.3. Details of the initialization models for RLHF (150 words)\n  8.4. Details of RLHF training (363 words, 1 figure)\n  8.5. FLAN and T0 models (287 words)\n9. Automatic evaluation details (1177 words)\n  9.1. Toxicity and bias evaluation details (155 words)\n  9.2. Prompt structure and evaluation features for each eval dataset (839 words)\n10. Additional results (2088 words, 2 figures)\n  10.1. Performance on public NLP datasets (80 words)\n  10.2. Reward model generalization across sets of labelers (140 words, 1 figure)\n  10.3. Metadata results as a function of model size (14 words)\n  10.4. Likert scores (39 words, 1 figure)\n  10.5. Measuring bias (534 words, 1 figure)\n  10.6. Fixing regressions on public NLP datasets (419 words, 3 figures)\n  10.7. Optimal KL reward coefficient (97 words, 1 figure)\n  10.8. PPO init models (97 words, 1 figure)\n  10.9. Learning rate optimization for PPO models (117 words, 1 figure)\n  10.10. RealToxicityPrompts results as a function of input toxicity (147 words, 3 figures)\n  10.11. Additional ablations (258 words)\n11. Model samples (3408 words)", "jarvis_1": "1. Introduction (1091 words, 3 figures)\n2. Challenges for Agents in open-world Environments (697 words)\n  2.1. Challenge I: Situation-Aware Planning (248 words)\n  2.2. Challenge II: Task Complexity (183 words)\n  2.3. Challenge III: Life-long Learning (204 words)\n3. Multi-task Agent with Memory-Augmented MLM (2422 words, 1 figure)\n  3.1. Overview (189 words)\n  3.2. Interactive Planning with MLM (600 words, 1 figure)\n  3.3. Planning with Multimodal Memory in the Loop (763 words)\n  3.4. Self-improving Agents (693 words)\n4. Experiments (2047 words)\n  4.1. Experimental Setups (431 words)\n  4.2. Main Results (399 words)\n  4.3. Ablation Studies (573 words, 1 figure)\n    4.3.1. JARVIS-1based on different LMs (342 words, 1 figure)\n    4.3.2. Ablation on Memory (142 words)\n  4.4. Long-Horizon Challenges (542 words)\n5. Related Works (613 words)\n  5.1. Planning with LLM (272 words)\n  5.2. Minecraft Agents (334 words)\n6. Conclusion (134 words)\n7. Acknowledgments (71 words)", "llama_2": "1. Introduction (1014 words, 3 figures)\n2. Pretraining (1530 words)\n  2.1. Pretraining Data (214 words)\n  2.2. Training Details (673 words, 1 figure)\n    2.2.1. Training Hardware & Carbon Footprint (435 words)\n  2.3. Llama 2Pretrained Model Evaluation (551 words)\n3. Fine-tuning (6202 words)\n  3.1. Supervised Fine-Tuning (SFT) (589 words)\n  3.2. Reinforcement Learning with Human Feedback (RLHF) (3769 words)\n    3.2.1. Human Preference Data Collection (757 words)\n    3.2.2. Reward Modeling (1630 words, 1 figure)\n    3.2.3. Iterative Fine-Tuning (1300 words, 2 figures)\n  3.3. System Message for Multi-Turn Consistency (656 words, 2 figures)\n  3.4. RLHF Results (1075 words)\n    3.4.1. Model-Based Evaluation (469 words, 1 figure)\n    3.4.2. Human Evaluation (602 words, 1 figure)\n4. Safety (6451 words)\n  4.1. Safety in Pretraining (1811 words, 1 figure)\n  4.2. Safety Fine-Tuning (2872 words)\n    4.2.1. Safety Categories and Annotation Guidelines (211 words)\n    4.2.2. Safety Supervised Fine-Tuning (95 words)\n    4.2.3. Safety RLHF (1426 words, 2 figures)\n    4.2.4. Context Distillation for Safety (899 words, 1 figure)\n  4.3. Red Teaming (827 words, 1 figure)\n  4.4. Safety Evaluation of Llama 2-Chat (809 words, 2 figures)\n5. Discussion (1784 words)\n  5.1. Learnings and Observations (1029 words, 4 figures)\n  5.2. Limitations and Ethical Considerations (295 words)\n  5.3. Responsible Release Strategy (407 words)\n6. Related Work (700 words)\n7. Conclusion (135 words)\n8. Appendix (14242 words)\n  8.1. Contributions (577 words)\n    8.1.1. Acknowledgments (400 words)\n  8.2. Additional Details for Pretraining (1386 words)\n    8.2.1. Architecture Changes Compared to Llama 1 (792 words, 1 figure)\n    8.2.2. Additional Details for Pretrained Models Evaluation (580 words)\n  8.3. Additional Details for Fine-tuning (3686 words)\n    8.3.1. Detailed Statistics of Meta Human Preference Data (417 words, 1 figure)\n    8.3.2. Curriculum Strategy for Meta Human Preference Data (128 words, 1 figure)\n    8.3.3. Ablation on Ranking Loss with Preference Rating-based Margin for Reward Modeling (326 words, 1 figure)\n    8.3.4. Ablation on Ranking Loss with Safety Auxiliary Loss for Reward Modeling (158 words)\n    8.3.5. Additional Results for GAtt (291 words, 1 figure)\n    8.3.6. How Far Can Model-Based Evaluation Go? (124 words, 1 figure)\n    8.3.7. Human Evaluation (2194 words, 2 figures)\n  8.4. Additional Details for Safety (6231 words)\n    8.4.1. Tension between Safety and Helpfulness in Reward Modeling (639 words, 1 figure)\n    8.4.2. Qualitative Results on Safety Data Scaling (2227 words)\n    8.4.3. English Pronouns (80 words)\n    8.4.4. Context Distillation Preprompts (15 words)\n    8.4.5. Safety Errors: False Refusals and Vague Responses (998 words, 1 figure)\n    8.4.6. Examples of Safety Evaluation (939 words)\n    8.4.7. Description of Automatic Safety Benchmarks (431 words)\n    8.4.8. Automatic Safety Benchmark Evaluation Results (862 words)\n  8.5. Data Annotation (669 words)\n    8.5.1. SFT Annotation Instructions (88 words)\n    8.5.2. Negative User Experience Categories (85 words)\n    8.5.3. Quality Assurance Process (159 words)\n    8.5.4. Annotator Selection (288 words)\n  8.6. Dataset Contamination (1133 words)\n  8.7. Model Card (534 words)", "muzero": "1. Introduction (548 words)\n2. Prior Work (604 words)\n3. MuZero Algorithm (1048 words, 1 figure)\n4. Results (1488 words, 1 figure)\n5. Conclusions (126 words)\n6. Acknowledgments (41 words)\n7. Supplementary Materials (48 words)\n8. Comparison to AlphaZero (415 words)\n9. Search (686 words)\n10. Hyperparameters (120 words)\n11. Data Generation (268 words)\n12. Network Input (501 words)\n  12.1. Representation Function (163 words)\n  12.2. Dynamics Function (332 words)\n13. Network Architecture (450 words)\n14. Training (438 words)\n15. Reanalyze (170 words)\n16. Evaluation (1847 words, 3 figures)", "resnet": "1. Introduction (855 words, 2 figures)\n2. Related Work (362 words)\n3. Deep Residual Learning (1522 words)\n  3.1. Residual Learning (305 words)\n  3.2. Identity Mapping by Shortcuts (416 words, 1 figure)\n  3.3. Network Architectures (589 words, 1 figure)\n  3.4. Implementation (199 words)\n4. Experiments (2678 words)\n  4.1. ImageNet Classification (1472 words, 2 figures)\n  4.2. CIFAR-10 and Analysis (1015 words, 1 figure)\n  4.3. Object Detection on PASCAL and MS COCO (174 words)\n5. Object Detection Baselines (584 words)\n6. Object Detection Improvements (1125 words)\n7. ImageNet Localization (866 words)", "transformer": "1. Introduction (283 words)\n2. Background (267 words)\n3. Model Architecture (1479 words, 1 figure)\n  3.1. Encoder and Decoder Stacks (204 words)\n  3.2. Attention (740 words)\n    3.2.1. Scaled Dot-Product Attention (280 words)\n    3.2.2. Multi-Head Attention (197 words, 1 figure)\n    3.2.3. Applications of Attention in our Model (190 words)\n  3.3. Position-wise Feed-Forward Networks (96 words)\n  3.4. Embeddings and Softmax (76 words)\n  3.5. Positional Encoding (232 words)\n4. Why Self-Attention (577 words)\n5. Training (345 words)\n  5.1. Training Data and Batching (86 words)\n  5.2. Hardware and Schedule (71 words)\n  5.3. Optimizer (70 words)\n  5.4. Regularization (96 words)\n6. Results (1223 words)\n  6.1. Machine Translation (421 words)\n  6.2. Model Variations (398 words)\n  6.3. English Constituency Parsing (392 words)\n7. Conclusion (174 words)\n8. Attention Visualizations (150 words, 3 figures)"}
